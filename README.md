# Enhancing Language Model Accuracy: The Power of a Few Labeled Examples

Team: Katherine Jijo - Hofstra Univeristy, Liang Zhang - Baurch College 

Description: Project with Anote AI, aimed at addressing challenges in Large Language Models (LLMs) like GPT-3.5 Turbo & BERT. Initially, LLMs necessitated extensive labeled data, which presented time and cost challenges. The complexities of real-world data, characterized by messiness and lack of structure, made effective analysis difficult.

To overcome these hurdles, we introduce an active learning approach, enhancing text classification accuracy. Similar to providing students with clear examples for better understanding, the strategy involves fine-tuning models through human feedback or providing more label examples.

## Accuracy Improvement

After fine-tuning the models with human feedback and additional labeled examples, we observed a consistent improvement in accuracy across different datasets. This result supports the effectiveness of the active learning approach in enhancing the models' understanding of specific domains.

## Finding

After fine-tuning the models with human feedback and additional labeled examples, we observed a consistent improvement in accuracy across different datasets. Notably, our experiments revealed that incorporating targeted training on areas where the model is weak played a pivotal role. This iterative approach allowed the model to gradually enhance its proficiency in handling specific domains.



